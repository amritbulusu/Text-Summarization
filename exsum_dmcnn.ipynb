{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import time\n",
    "from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(dirname):\n",
    "    df = pd.DataFrame(columns = ['text', 'summary', 'target', 'entities'])\n",
    "    for filename in os.listdir(dirname):\n",
    "        if filename.endswith('.summary'):\n",
    "            pathname = os.path.join(dirname, filename)\n",
    "            textfile = open(pathname, encoding='utf8')\n",
    "            contents = textfile.read()\n",
    "            entries = []\n",
    "            for entry in contents.split('\\n\\n'):\n",
    "                entries.append(entry)\n",
    "            a = entries[1]\n",
    "            a = a.split('\\n')\n",
    "            target = []\n",
    "            text = ''\n",
    "            for i in range(len(a)):\n",
    "                text += str(a[i].split('\\t\\t\\t')[0])+'\\n\\n'\n",
    "                target.append(a[i].split('\\t\\t\\t')[1])\n",
    "            dict1 = {}\n",
    "            for i in range(len(entries[3].split('\\n'))):\n",
    "                dict1[str(entries[3].split('\\n')[i].split(':')[0])] = str(entries[3].split('\\n')[i].split(':')[1])\n",
    "            sentences = text.split('\\n\\n')\n",
    "            sent = entries[2].split('\\n\\n')\n",
    "            for i in range(len(sentences)):\n",
    "                tokens = sentences[i].split()\n",
    "                for j in range(len(tokens)):\n",
    "                    if tokens[j] in dict1:\n",
    "                        tokens[j] = dict1[tokens[j]]\n",
    "                sentences[i] = \" \".join(tokens)\n",
    "            for i in range(len(sent)):\n",
    "                token = sent[i].split()\n",
    "                for j in range(len(token)):\n",
    "                    if token[j] in dict1:\n",
    "                        token[j] = dict1[token[j]]\n",
    "                sent[i] = \" \".join(token)\n",
    "            text = \"\\n\\n\".join(sentences)\n",
    "            summary = \"\\n\\n\".join(sent)\n",
    "            l = [str(text), str(summary), target, dict1]\n",
    "            df2 = pd.DataFrame([l], columns=['text', 'summary', 'target', 'entities'])\n",
    "            df = df.append(df2, ignore_index=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-378e35be2fcf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/dataset/training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-4e8ed9d1fe68>\u001b[0m in \u001b[0;36mload\u001b[1;34m(dirname)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'summary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'target'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'entities'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.summary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mpathname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = load('/dataset/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = []\n",
    "for i in range(len(df[\"text\"])):\n",
    "    a = df[\"text\"][i].split('\\n\\n')\n",
    "    documents.append(a[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = []\n",
    "for i in range(len(df[\"target\"])):\n",
    "    targets.append(df[\"target\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stopwords_removal=False, stemming=False):\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r\" ' \", \" \", text)\n",
    "    str1 = re.findall(\"[@a-zA-Z0-9]* '[a-zA-Z]\", text)\n",
    "    for l in str1:\n",
    "        text= re.sub(l,l.replace(\" \",\"\"),text)\n",
    "    text = re.findall(r\"[\\w']+\", text)\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word in contractions:\n",
    "            new_text.append(contractions[word])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    text = \" \".join(new_text)\n",
    "    tokens = text.split()\n",
    "    words = []\n",
    "    if stopwords_removal:\n",
    "        for token in tokens:\n",
    "            if token not in cachedStopWords:\n",
    "                words.append(token)\n",
    "            text = \" \".join(words)        \n",
    "    words = []\n",
    "    if stemming:\n",
    "        for token in tokens:\n",
    "            words.append(stem(token))\n",
    "        text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(documents)):\n",
    "    for j in range(len(documents[i])):\n",
    "        documents[i][j] = preprocess(documents[i][j], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__pickleStuff(\"documents.p\",documents)\n",
    "__pickleStuff(\"targets.p\",targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = __loadStuff(\"documents.p\")\n",
    "targets = __loadStuff(\"targets.p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings: 1917248\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('/numberbatch/numberbatch.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split(' ')\n",
    "        word = values[0]\n",
    "        embedding = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = embedding\n",
    "\n",
    "print('Word embeddings:', len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(count_dict, documents):\n",
    "    for i in range(len(documents)):\n",
    "        for sentence in documents[i]:\n",
    "            for word in sentence.split():\n",
    "                if word not in count_dict:\n",
    "                    count_dict[word] = 1\n",
    "                else:\n",
    "                    count_dict[word] += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary : 416253\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "\n",
    "count_words(word_counts, documents)\n",
    "\n",
    "print(\"Size of vocabulary :\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from CN: 85188\n",
      "Percent of words that are missing from vocabulary: 20.47%\n"
     ]
    }
   ],
   "source": [
    "missing_words = 0\n",
    "threshold = 15\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count>threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "missing_ratio = round(missing_words/len(word_counts), 4)*100\n",
    "\n",
    "print(\"Number of words missing from CN:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('metodiev', 25),\n",
       " ('portfolios', 65),\n",
       " ('jiabao', 71),\n",
       " ('mh17', 1192),\n",
       " (\"huguely's\", 26),\n",
       " ('router', 89),\n",
       " ('verges', 103),\n",
       " ('thermomix', 158),\n",
       " ('cuban', 1153),\n",
       " ('laxey', 31),\n",
       " ('frowning', 51),\n",
       " ('kissed', 1210),\n",
       " ('fortifications', 62),\n",
       " ('attire', 746),\n",
       " ('airspeed', 36),\n",
       " ('reuters', 2012),\n",
       " ('themed', 1840),\n",
       " ('celta', 259),\n",
       " ('triggers', 524),\n",
       " ('liquidator', 19),\n",
       " ('padang', 28),\n",
       " ('ketosis', 21),\n",
       " ('islamophobic', 64),\n",
       " ('blindness', 466),\n",
       " ('meter', 803),\n",
       " ('liege', 189),\n",
       " ('unamused', 27),\n",
       " ('daze', 84),\n",
       " ('houndstooth', 22),\n",
       " ('kerosene', 105)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_words = []\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold and word not in embeddings_index:\n",
    "        missing_words.append((word,count))\n",
    "missing_words[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 416253\n",
      "Number of words we will use: 88037\n",
      "Percent of words we will use: 21.15%\n"
     ]
    }
   ],
   "source": [
    "#dictionary to convert words to integers\n",
    "vocab_to_int = {} \n",
    "# Index words from 0\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88037\n"
     ]
    }
   ],
   "source": [
    "# Need to use 300 for embedding dimensions to match CN's vectors.\n",
    "embedding_dim = 300\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_ints(docs, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for text in docs:    \n",
    "        for sentence in text:\n",
    "            sentence_ints = []\n",
    "            for word in sentence.split():\n",
    "                word_count += 1\n",
    "                if word in vocab_to_int:\n",
    "                    sentence_ints.append(vocab_to_int[word])\n",
    "                else:\n",
    "                    sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                    unk_count += 1\n",
    "            if eos:\n",
    "                sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "            ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count = 0\n",
    "unk_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in documents: 76674995\n",
      "Total number of UNKs in documents: 999119\n",
      "Percent of words that are UNK: 1.3%\n"
     ]
    }
   ],
   "source": [
    "int_texts, word_count, unk_count = convert_to_ints(documents, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in documents:\", word_count)\n",
    "print(\"Total number of UNKs in documents:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(int_texts[:3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lengths(text):\n",
    "    '''Create a data frame of the sentence lengths from a text'''\n",
    "    lengths = []\n",
    "    for sentence in text:\n",
    "        lengths.append(len(sentence))\n",
    "    return pd.DataFrame(lengths, columns=['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_lengths= create_lengths(int_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n",
      "35.0\n",
      "56.0\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(text_lengths.counts, 90))\n",
    "print(np.percentile(text_lengths.counts, 95))\n",
    "print(np.percentile(text_lengths.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def __pickleStuff(filename, stuff):\n",
    "    save_stuff = open(filename, \"wb\")\n",
    "    pickle.dump(stuff, save_stuff)\n",
    "    save_stuff.close()\n",
    "def __loadStuff(filename):\n",
    "    saved_stuff = open(filename,\"rb\")\n",
    "    stuff = pickle.load(saved_stuff)\n",
    "    saved_stuff.close()\n",
    "    return stuff\n",
    "\n",
    "# __pickleStuff(\"documents.p\",documents)\n",
    "# __pickleStuff(\"targets.p\",targets)\n",
    "\n",
    "# __pickleStuff(\"int_texts.p\",int_texts)\n",
    "# __pickleStuff(\"text_lenghts.p\",text_lengths)\n",
    "# __pickleStuff(\"word_embedding_matrix.p\",word_embedding_matrix)\n",
    "\n",
    "# __pickleStuff(\"vocab_to_int.p\",vocab_to_int)\n",
    "# __pickleStuff(\"int_to_vocab.p\",int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documents = __loadStuff(\"/dataset/documents.p\")\n",
    "targets = __loadStuff(\"targets.p\")\n",
    "\n",
    "# int_texts = __loadStuff(\"/dataset/int_texts.p\")\n",
    "# text_lengths = __loadStuff(\"/dataset/text_lenghts.p\")\n",
    "# word_embedding_matrix = __loadStuff(\"/dataset/word_embedding_matrix.p\")\n",
    "\n",
    "# vocab_to_int = __loadStuff(\"/dataset/vocab_to_int.p\")\n",
    "# int_to_vocab = __loadStuff(\"/dataset/int_to_vocab.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    inputs_X = tf.placeholder(tf.int32, [None, None], name='inputs_X')\n",
    "    inputs_Y = tf.placeholder(tf.float32, [None, None], name='inputs_Y')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    seq_length = tf.placeholder(tf.int32, (None,), name='seq_length')\n",
    "    max_seq_length = tf.reduce_max(seq_length, name='max_seq_length')\n",
    "    \n",
    "    return inputs_X, inputs_Y, lr, seq_length, max_seq_length, keep_prob\n",
    "\n",
    "\n",
    "def process_rnn_input(target_data, vocab_to_int, batch_size):  \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1]) # slice it to target_data[0:batch_size, 0: -1]\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input\n",
    "\n",
    "\n",
    "def unirnn_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope(\"rnn_{}\".format(layer)):\n",
    "            single_cell = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "            single_cell = tf.contrib.rnn.DropoutWrapper(single_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "\n",
    "            enc_output, enc_state = tf.nn.dynamic_rnn(single_cell, rnn_inputs, sequence_length, dtype=tf.float32)\n",
    "    \n",
    "    return enc_output, enc_state\n",
    "\n",
    "\n",
    "def birnn_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope(\"birnn_{}\".format(layer)):\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size, initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, input_keep_prob = keep_prob)\n",
    "            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, rnn_inputs, sequence_length, dtype=tf.float32)\n",
    "            \n",
    "            enc_output = tf.concat(enc_output, 2)\n",
    "            enc_state = tf.concat(enc_state, 2)\n",
    "            \n",
    "    return enc_output, enc_state\n",
    "\n",
    "\n",
    "\n",
    "def sequence_classifier(input_data, target_data, num_classes, keep_prob, text_length, max_seq_length, \n",
    "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n",
    "    embeddings = word_embedding_matrix\n",
    "    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    print(enc_embed_input.shape)\n",
    "    all_outputs, state = unirnn_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n",
    "#     print(state.get_shape())\n",
    "    outputs = state[0]\n",
    "            \n",
    "#     logits_rnn = rnn_softmax(outputs)\n",
    "    with tf.variable_scope(\"rnn_softmax\"):\n",
    "        W_softmax = tf.get_variable(\"W_softmax\", [300, num_classes])\n",
    "        b_softmax = tf.get_variable(\"b_softmax\", [num_classes])\n",
    "    logits_rnn = tf.matmul(outputs, W_softmax) + b_softmax\n",
    "    \n",
    "    return logits_rnn\n",
    "\n",
    "\n",
    "\n",
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(target_data, texts, batch_size):\n",
    "    \"\"\"Batch targets, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        targets_batch = target_data[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch), dtype=np.float)\n",
    "#         targets_batches = np.array(targets_batch)\n",
    "#         print(targets_batch.shape)\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        pad_texts_lengths = np.array(pad_texts_lengths, dtype=np.float)\n",
    "        \n",
    "        yield targets_batch, pad_texts_batch, pad_texts_lengths\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets_y = []\n",
    "\n",
    "for i in range(len(targets)):\n",
    "    for j in range(len(targets[i])):\n",
    "        targets_y.append(targets[i][j])\n",
    "\n",
    "for i in range(len(targets_y)):\n",
    "    if targets_y[i] == str(2):\n",
    "        targets_y[i] = \"0\"\n",
    "        \n",
    "targets_y = np.asarray(targets_y, dtype=np.float)\n",
    "targets_y = targets_y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "targetsenc = enc.fit_transform(targets_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targetsenc = targetsenc.toarray()\n",
    "int_texts = np.asarray(int_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<PAD>' has id: 88034\n",
      "pad texts batch samples:\n",
      "\r",
      " [[ 65211.  88035.  88034.  88034.  88034.  88034.  88034.  88034.  88034.\n",
      "   88034.  88034.  88034.  88034.  88034.  88034.]\n",
      " [ 10174.  88033.  15435.  88035.  88034.  88034.  88034.  88034.  88034.\n",
      "   88034.  88034.  88034.  88034.  88034.  88034.]\n",
      " [ 31686.  88033.  22055.  25918.  71160.  14639.  84793.   1036.  29593.\n",
      "   42605.  26617.  77459.  18333.  25278.  88035.]\n",
      " [ 31686.  28681.  50739.  67122.  66741.  19572.  12396.  88035.  88034.\n",
      "   88034.  88034.  88034.  88034.  88034.  88034.]\n",
      " [ 31686.  69477.  37647.  41305.  74368.  22722.  46160.  88035.  88034.\n",
      "   88034.  88034.  88034.  88034.  88034.  88034.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"'<PAD>' has id: {}\".format(vocab_to_int['<PAD>']))\n",
    "targets_samples = targets_y[7:50]\n",
    "texts_samples = int_texts[7:50]\n",
    "targets_batch_samples, pad_texts_batch_samples, pad_texts_lengths_samples = next(get_batches(\n",
    "    targets_samples, texts_samples, 5))\n",
    "print(\"pad texts batch samples:\\n\\r {}\".format(pad_texts_batch_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the Hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "rnn_size = 300\n",
    "num_layers = 3\n",
    "num_classes = 3\n",
    "learning_rate = 0.0025\n",
    "keep_probability = 0.95\n",
    "max_gradient_norm = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 300)\n",
      "Graph is built.\n",
      "./graph\n"
     ]
    }
   ],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    inputs_X, inputs_Y, lr, seq_length, max_seq_length, keep_prob = model_inputs()\n",
    "    \n",
    "    logs = sequence_classifier(inputs_X, inputs_Y, num_classes, keep_prob, seq_length, max_seq_length, \n",
    "                  len(vocab_to_int)+1, rnn_size, num_layers, vocab_to_int, batch_size)\n",
    "#     print(logs.shape)\n",
    "    predictions = tf.nn.softmax(logs)\n",
    "    predictions = tf.identity(predictions, name='predictions')\n",
    "#     print(predictions.shape)\n",
    "    accuracy = tf.equal(tf.argmax(inputs_Y,1), tf.argmax(predictions,1))\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logs, labels=inputs_Y))\n",
    "    \n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        trainable_vars = tf.trainable_variables()\n",
    "        \n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(loss, trainable_vars), max_gradient_norm)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        train_optimizer = optimizer.apply_gradients(zip(grads, trainable_vars))\n",
    "\n",
    "print(\"Graph is built.\")\n",
    "graph_location = \"./graph\"\n",
    "print(graph_location)\n",
    "train_writer = tf.summary.FileWriter(graph_location)\n",
    "train_writer.add_graph(train_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/100 Batch   20/39584 - Loss:  1.082, Seconds: 15.85\n",
      "Accuracy is:  0.3828125\n",
      "Epoch   1/100 Batch   40/39584 - Loss:  0.615, Seconds: 16.18\n",
      "Accuracy is:  0.3828125\n",
      "Epoch   1/100 Batch   60/39584 - Loss:  0.614, Seconds: 13.06\n",
      "Accuracy is:  0.421875\n",
      "Epoch   1/100 Batch   80/39584 - Loss:  0.612, Seconds: 23.94\n",
      "Accuracy is:  0.40625\n",
      "Epoch   1/100 Batch  100/39584 - Loss:  0.612, Seconds: 14.42\n",
      "Accuracy is:  0.4609375\n",
      "Epoch   1/100 Batch  120/39584 - Loss:  0.611, Seconds: 18.50\n",
      "Accuracy is:  0.40625\n",
      "Epoch   1/100 Batch  140/39584 - Loss:  0.613, Seconds: 20.18\n",
      "Accuracy is:  0.4140625\n",
      "Epoch   1/100 Batch  160/39584 - Loss:  0.613, Seconds: 19.52\n",
      "Accuracy is:  0.4296875\n",
      "Epoch   1/100 Batch  180/39584 - Loss:  0.612, Seconds: 26.45\n",
      "Accuracy is:  0.4375\n",
      "Epoch   1/100 Batch  200/39584 - Loss:  0.611, Seconds: 22.02\n",
      "Accuracy is:  0.4296875\n",
      "Epoch   1/100 Batch  220/39584 - Loss:  0.612, Seconds: 21.53\n",
      "Accuracy is:  0.421875\n",
      "Epoch   1/100 Batch  240/39584 - Loss:  0.610, Seconds: 17.56\n",
      "Accuracy is:  0.4375\n",
      "Epoch   1/100 Batch  260/39584 - Loss:  0.611, Seconds: 36.64\n",
      "Accuracy is:  0.40625\n",
      "Epoch   1/100 Batch  280/39584 - Loss:  0.610, Seconds: 71.30\n",
      "Accuracy is:  0.4375\n",
      "Epoch   1/100 Batch  300/39584 - Loss:  0.614, Seconds: 37.59\n",
      "Accuracy is:  0.390625\n",
      "Epoch   1/100 Batch  320/39584 - Loss:  0.611, Seconds: 14.93\n",
      "Accuracy is:  0.390625\n",
      "Epoch   1/100 Batch  340/39584 - Loss:  0.611, Seconds: 58.18\n",
      "Accuracy is:  0.4296875\n",
      "Epoch   1/100 Batch  360/39584 - Loss:  0.612, Seconds: 23.04\n",
      "Accuracy is:  0.4140625\n",
      "Epoch   1/100 Batch  380/39584 - Loss:  0.612, Seconds: 29.58\n",
      "Accuracy is:  0.4375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-55835a3923ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m                  \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                  \u001b[0mseq_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_texts_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                  keep_prob: keep_probability})\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlosss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "learning_rate_decay = 0.55\n",
    "min_learning_rate = 0.0005\n",
    "display_step = 20 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 7 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 3 # Make 3 update checks per epoch\n",
    "update_check = (len(int_texts)//batch_size//per_epoch)-1\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "classifier_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "classifier_accuracy = []\n",
    "predict = []\n",
    "\n",
    "checkpoint = \"./best_model_classifier.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    #loader = tf.train.import_meta_graph(\"./\" + checkpoint + '.meta')\n",
    "    #loader.restore(sess, checkpoint)\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (targets_batch, pad_texts_batch, pad_texts_lengths) in enumerate(\n",
    "                get_batches(targetsenc, int_texts, batch_size)):\n",
    "            start_time = time.time()\n",
    "#             print(type(pad_texts_batch), type(targets_batch), type(pad_texts_lengths))\n",
    "            _, losss, accuracyy, logets = sess.run(\n",
    "                [train_optimizer, loss, accuracy, predictions],\n",
    "                {inputs_X: pad_texts_batch,\n",
    "                 inputs_Y: list(targets_batch),\n",
    "                 lr: learning_rate,\n",
    "                 seq_length: list(pad_texts_lengths),\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += losss\n",
    "            update_loss += losss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "            predict.append(logets)\n",
    "            \n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(int_texts) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                print(\"Accuracy is: \", np.mean(accuracyy))\n",
    "                classifier_accuracy.append(accuracyy)\n",
    "                batch_loss = 0\n",
    "\n",
    "            if batch_i % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                classifier_update_loss.append(update_loss)\n",
    "                print(\"Average accuracy for this update %.3f\" % np.mean(classifier_accuracy))\n",
    "                \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(classifier_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = load(r'C:\\Users\\amrit\\OneDrive\\Desktop\\Thesis\\Data\\Dataset\\cnnanddailymail\\test')\n",
    "test_docs = []\n",
    "\n",
    "for i in range(len(test[\"text\"])):\n",
    "    a = test[\"text\"][i].split('\\n\\n')\n",
    "    test_docs.append(a[:-1])\n",
    "\n",
    "test_targets = []\n",
    "for i in range(len(test[\"target\"])):\n",
    "    test_targets.append(test[\"target\"][i])\n",
    "    \n",
    "test_summaries = []\n",
    "for i in range(len(test[\"target\"])):\n",
    "    test_summaries.append(test[\"summary\"][i])\n",
    "    \n",
    "# def prep_text(sentence):\n",
    "#     sentence = preprocess(sentence)\n",
    "#     return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in sentence.split()]\n",
    "\n",
    "# texts = []\n",
    "\n",
    "# for document in test_docs:\n",
    "#     for sentence in document:\n",
    "#         texts.append(prep_text(sentence))\n",
    "\n",
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# texts = __loadStuff(\"test_texts.p\")\n",
    "test_docs = __loadStuff(\"test_docs.p\")\n",
    "test_targets = __loadStuff(\"test_targets.p\")\n",
    "for i in range(len(test_docs)):\n",
    "    for j in range(len(test_docs[i])):\n",
    "        test_docs[i][j] = preprocess(test_docs[i][j], False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /checkpoint/./best_model_classifier.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"/checkpoint/./best_model_classifier.ckpt\"\n",
    "loaded_graph = tf.Graph()\n",
    "answer_logits = []\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "    inputs_X = loaded_graph.get_tensor_by_name('inputs_X:0')\n",
    "    predictions = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    seq_length = loaded_graph.get_tensor_by_name('seq_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    for i, text in enumerate(texts):\n",
    "        answers = sess.run(predictions, {inputs_X: [text]*batch_size,\n",
    "                 seq_length: [len(text)]*batch_size,\n",
    "                 keep_prob: 1.0})\n",
    "        answer_logits.append(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer_logits = __loadStuff(\"answer_logits.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = []\n",
    "for i in range(len(answer_logits)):\n",
    "    answers.append(answer_logits[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answers = np.asarray(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264305, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yo = np.argmax(answers, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 34308, 1: 229997})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(list(yo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_docs_summaries = [[]]\n",
    "test_output = pd.DataFrame(columns = ['document', 'targets', 'summary', 'predicted_summary'])\n",
    "\n",
    "test_output[\"document\"] = test_docs\n",
    "test_output[\"targets\"] = test_targets\n",
    "test_output[\"summary\"] = test_summaries\n",
    "\n",
    "# for i in range(len(test_output[\"document\"])):\n",
    "#     temp = []\n",
    "#     for j in range(len(test_output[\"document\"][i])):\n",
    "#         if int(test_output[\"targets\"][i][j]) == 1:\n",
    "#             temp.append(test_docs[i][j])\n",
    "#     test_output[\"predicted_summary\"][i] = temp\n",
    "\n",
    "count = 0\n",
    "counts = 0\n",
    "for i in range(len(test_output[\"document\"])):\n",
    "    temp = []\n",
    "    for j in range(len(test_output[\"document\"][i])):\n",
    "        if int(yo[count-1]) == 1 and answers[count-1][1] > 0.99:\n",
    "            temp.append(test_output[\"document\"][i][j])\n",
    "        count += 1\n",
    "    test_output[\"predicted_summary\"][i] = temp\n",
    "\n",
    "# c = 0\n",
    "\n",
    "# for i in range(len(test_output[\"document\"])):\n",
    "#     temp = []\n",
    "#     index = list(range(c, c+len(test_output[\"document\"][i])))\n",
    "#     try:\n",
    "#         index = np.sort(np.argpartition(answers[index][:, 1], -4)[-4:])\n",
    "#     except:\n",
    "#         index = np.sort(index)\n",
    "#     for j in range(len(test_output[\"document\"][i])):\n",
    "#         if j in index:\n",
    "#             temp.append(test_output[\"document\"][i][j])\n",
    "#     test_output[\"predicted_summary\"][i] = temp\n",
    "#     c += len(test_output[\"document\"][i])\n",
    "    \n",
    "    \n",
    "for i in range(len(test_output[\"predicted_summary\"])):\n",
    "    test_output[\"predicted_summary\"][i] = \". \".join(test_output[\"predicted_summary\"][i])\n",
    "# #     test_output[\"summary\"][i] = \". \".join(test_output[\"summary\"][i])\n",
    "\n",
    "__pickleStuff(\"test_output_more.p\",test_output)\n",
    "\n",
    "# for i in range(len(test_output[\"document\"])):\n",
    "#     test_output[\"document\"][i] = \". \".join(test_output[\"document\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyps, refs = map(list, zip(*[[test_output[\"predicted_summary\"][i], test_output[\"summary\"][i]] for i in range(len(test_output))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Emma Hannigan had her breasts and ovaries removed in 2006 to reduce her risk of cancer after she was diagnosed with the faulty BRCA1 gene a mother - of - two has battled cancer nine times in the last seven years , despite having her breasts and ovaries removed to try and prevent the disease. Emma Hannigan was told in 2005 that she carried the faulty BRCA1 gene , which increases a woman \\'s chance of getting breast cancer by 85 per cent , and ovarian cancer by 50 per cent. she opted to have a double mastectomy and oophorectomy the following year , to reduce her risk. since that point , mrs Emma Hannigan has battled the disease a staggering nine times , including four bouts in the space of a year. she is now undergoing chemotherapy every three weeks as specialists try to keep the disease at bay. mrs Emma Hannigan , an author from Bray , near Dublin , said despite it failing to prevent cancer , she does not regret having preventative surgery. the Breast Cancer Campaign estimates preventative mastectomy is thought to reduce breast cancer risk in carriers of the brca gene , by 90 per cent. the odds reduce a woman \\'s risk to lower than that of the average for women who do not carry the mutated gene. \\' it was n\\'t a difficult decision. it was a no - brainer - i wanted to live. \\' i was tested because there was a family history of breast and ovarian cancer in my family , \\' she said. my other aunts , Ruth and Cathy , survived breast cancer in their 30s and 40s. my great aunt , Anneliese , died from ovarian cancer. \\' when gene testing came in my family were invited to have tests. \\' so i was tested and i was diagnosed too. \\' it was not difficult. i only had to look at them and know that i had made the right choice. \\' following the mastectomy , her breast tissue was sent away for testing. the results showed early signs of cancer. she underwent treatment , including radiation , pictured , and within a few months doctors told her she was in remission since 2007 , mrs Emma Hannigan , an author , has battled the disease nine times , including facing four bouts in one year. she is currently undergoing chemotherapy as specialists try to keep the disease at bay but doctors said they were pre-cancerous cells , and she was clear of the disease at the time. in june 2007 , she was diagnosed with breast cancer. \\' in january 2007 i had muscle pains and a rash , \\' the former beautician said. women with a significant family history of breast cancer may have an increased risk of getting the disease. a significant family history is defined by : women who inherit the faulty , or mutated , BRCA1 or BRCA2 genes have a 50 to 80 per cent chance of developing breast cancer during their lifetime. genetic tests are available to women who are likely to have a BRCA1 or BRCA2 mutation , or faults in two other genes called TP53 and PTEN. BRCA1 gene faults are more common in the Ashkenazi Jewish population , about 2.3 per cent of Ashkenazi Jewish women have a BRCA1 gene mutation. source : Breast Cancer Campaign \\' between february and april i was in and out of hospital. \\' i had iv chemotherapy used to treat both conditions , along with steroids to stop the dermatomyositis. \\' after a few months of treatment , doctors told the mother - of - two she was in remission. \\' i thought it was over , \\' she said. both times she was treated with chemotherapy and went into remission with scans and blood tests coming back clear. then in 2010 , mrs Emma Hannigan was diagnosed with cancer four times and was treated with a mixture of chemotherapy and radiation. each time she went into remission. again she went into remission. \\' this was the worst , \\' she said. \\' i could n\\'t move my head. she has had a successful career as an author writing such books as Driving Home for Christmas and The Secrets We Share. \\' currently the cancer is gone – but i \\'m having chemo every three weeks as a precaution , \\' she said. \\' the words , \" it is breast cancer \" are never easy to hear. \\' all the cancer is classed as breast cancer as this was the primary source – the place where it first started. \\' each time i was diagnosed it was in my lymph nodes in the area around my neck , shoulder , underarm and or the back of my head. mrs Emma Hannigan said : \\' Cancer does n\\'t get any less scary. \\' the words , \" it is breast cancer \" are never easy to hear. \\' she said she is no better than anyone else at beating cancer , rather treatments have improved \\' each time i found the cancer myself in the form of lumps just under the skin. i go to the doctor and am treated. \\' then i have scans and blood tests and it is clear. \\' my husband , Cian , 41 , and i crack open the champagne. \\' she said she was no better at beating cancer than other people , rather treatments have improved. \\' sometimes i wonder , \" why i have had it nine times when some people get it once ? \" \\' there \\'s no reason. \\' but it \\'s their choice , \\' she said. from every bottle sold in Waitrose , TanOrganic will donate 35p to cancer research charities .',\n",
       " 'Emma Hannigan was diagnosed with the faulty BRCA1 gene in 2005 a year later she had her breasts and ovaries removed to prevent cancer but in 2007 , despite the surgery , she was diagnosed with breast cancer since then she has battled the disease nine times - four times in one year')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyps[1000], refs[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "\n",
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(hyps, refs, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.3166465820724625,\n",
       "  'p': 0.23719313818615717,\n",
       "  'r': 0.5189164351979545},\n",
       " 'rouge-2': {'f': 0.10851889169484978,\n",
       "  'p': 0.07778537811667763,\n",
       "  'r': 0.20453484693224744},\n",
       " 'rouge-l': {'f': 0.13129653532644522,\n",
       "  'p': 0.12235640579384106,\n",
       "  'r': 0.337026191124659}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>targets</th>\n",
       "      <th>summary</th>\n",
       "      <th>predicted_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Neil Redfearn is considering his position as ...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, ...</td>\n",
       "      <td>Steve Thompson suspended by Leeds just *19* *g...</td>\n",
       "      <td>Leeds took two months to appoint Steve Thompso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[she 's a best - selling singer , actress , fa...</td>\n",
       "      <td>[2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "      <td>Rita , 24 , models in colourful new Rimmel bea...</td>\n",
       "      <td>Rita has been unveiled as the face of Rimmel '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the handsome Italy maths teacher who has take...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>Pietro Boselli , 26 , from Brescia in Italy ta...</td>\n",
       "      <td>the handsome Italy maths teacher who has taken...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[former Manchester United and Manchester City ...</td>\n",
       "      <td>[1, 2, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1]</td>\n",
       "      <td>Tevez played for Manchester United , Mancheste...</td>\n",
       "      <td>the Argentinian , who has scored 36 goals in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[it is a conversation that will be familiar to...</td>\n",
       "      <td>[2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0, ...</td>\n",
       "      <td>Nick Clegg made the *admission* in a rare join...</td>\n",
       "      <td>in a joint interview with his high flying lawy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  [Neil Redfearn is considering his position as ...   \n",
       "1  [she 's a best - selling singer , actress , fa...   \n",
       "2  [the handsome Italy maths teacher who has take...   \n",
       "3  [former Manchester United and Manchester City ...   \n",
       "4  [it is a conversation that will be familiar to...   \n",
       "\n",
       "                                             targets  \\\n",
       "0  [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, ...   \n",
       "1         [2, 1, 1, 2, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0]   \n",
       "2  [1, 1, 1, 0, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, ...   \n",
       "3               [1, 2, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1]   \n",
       "4  [2, 0, 1, 1, 1, 1, 0, 1, 0, 2, 2, 2, 0, 2, 0, ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Steve Thompson suspended by Leeds just *19* *g...   \n",
       "1  Rita , 24 , models in colourful new Rimmel bea...   \n",
       "2  Pietro Boselli , 26 , from Brescia in Italy ta...   \n",
       "3  Tevez played for Manchester United , Mancheste...   \n",
       "4  Nick Clegg made the *admission* in a rare join...   \n",
       "\n",
       "                                   predicted_summary  \n",
       "0  Leeds took two months to appoint Steve Thompso...  \n",
       "1  Rita has been unveiled as the face of Rimmel '...  \n",
       "2  the handsome Italy maths teacher who has taken...  \n",
       "3  the Argentinian , who has scored 36 goals in t...  \n",
       "4  in a joint interview with his high flying lawy...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__pickleStuff(\"test_output.p\",test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def __loadStuff(filename):\n",
    "    saved_stuff = open(filename,\"rb\")\n",
    "    stuff = pickle.load(saved_stuff)\n",
    "    saved_stuff.close()\n",
    "    return stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_output = __loadStuff(\"test_output.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"an ex-wife of a North Carolina man serving life in prison for the murder of his third wife has opened up about the abuse she faced when she was married to the man. Casey , also of North Carolina , was married to Michael Wilkie for four years and had a daughter with him before the couple divorced. he went on to marry his third wife , Shelby Wilkie. Michael Wilkie was found guilty of first - degree murder in january for the 2012 killing of Shelby Wilkie and is serving a life sentence without parole. Casey has opened up about the abuse she faced at the hands of Michael Wilkie , who in january was found guilty of the 2012 murder of his third wife ' he said if i ever tried to take his daughter away from him that he would kill me , ' Casey told ABC 's 20/20. Casey and Shelby Wilkie had met Michael Wilkie through an online dating site. Casey said they dated for a year - and - a - half before getting married. ' he was very friendly , very charming , easy to talk to , very soft spoken , and he had a good job and seemed to be pretty good , ' Casey said. a couple months after marrying in 2004 , Michael Wilkie began controlling aspects of Casey 's life and alienating himself from Casey 's daughter from a previous marriage , Casey said. ' if i planned to do something with one of my friends , he would manipulate the situation , and there would be something that came up that would interfere or get in the way , ' she said. and then he began to get physically abusive and attacked her when she was pregnant with their daughter. he grabbed me around my throat and threw me around our bedroom and on the bed. my shoulder went through and made that hole in the sheetrock in the bedroom , ' she said. Michael Wilkie ( left ) was sentenced to life in prison with no parole for killing his third wife , Shelby Wilkie ( right ). Shelby Wilkie and Michael Wilkie , both of North Carolina , had met on an online dating site but Casey never reported the incident and her friends and family were not aware of Michael Wilkie 's abusive side because ' he was so good at masking '. ' it was like Jekyll and Hyde : two personalities and you did n't know which one you would get , ' Casey said. ' you did n't know which one. you would meet when you got home. ' she said she ' had thoughts ' that Michael Wilkie would kill her , ' mainly because he told me he would kill me '. but Casey did n't leave Michael Wilkie for quite some time. ' i am the type of person that i will stay in a situation , whether it 's a job or a marriage … longer than i should because i do n't give up hope easily , ' she told 20/20. ' and i am always thinking about , ' what could i do to make it better ? ' after an argument about pictures taken of their daughters together in 2006 , Casey left Michael Wilkie. she took her older daughter but left the couple 's three - year - old behind. the couple later divorced in 2008. Casey eventually remarried and gained joint - custody of her and Michael Wilkie 's child , and met her former husband 's new wife , Shelby Wilkie , at a school event for their daughter. Shelby Wilkie was murdered in 2012 and her remains were found after a long search. her and Michael Wilkie 's child , Sydney ( left ) , is in the process of being adopted by Shelby Wilkie 's brother , Bill Sprowls , Jr , against Michael Wilkie ’s wishes she did not , however , warn Shelby Wilkie about the abuse she faced when she was married to Michael Wilkie. ' i had hoped that things had changed , and that it was me and not , you know , him. and that way , hey , he could be happy. she could be happy , and it could be a nice household environment , ' Casey said about the couple. just before Shelby Wilkie went missing the pair did have a short conversation. ' she said , ' i just want to ask you some things about Michael Wilkie , is that ok ? ' and i said , ' sure , ' Casey recalled. ' and i said , ' Shelby Wilkie , if there is anybody that knows what you are going through , it 's me. ' Casey told Shelby Wilkie she had to go shortly after and asked her to call her back. she never got a call back , and instead saw Michael Wilkie pleading for Shelby Wilkie to come home. Casey ( right ) married Michael Wilkie in 2004. she said a few months after the wedding be become controlling and eventually physically abusive. at times , she said she feared he would kill her at first , Casey thought that Shelby Wilkie had run from her husband , but Michael Wilkie was then arrested , charged and found guilty of his wife 's murder. Shelby Wilkie had filed two domestic violence charges against her husband before her death , but both were voluntarily dismissed , according to WSOC. blood and her ashes , along with a charred bracelet her mother had given her , were later found and Michael Wilkie was arrested , according to ABC. and it was n't until his arrest that Casey finally felt safe , she said. ' it 's made me grow as a person , ' she said. ' and it has made me stronger as a human being\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\". \".join(test_output.document[7111])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"an ex-wife of a North Carolina man serving life in prison for the murder of his third wife has opened up about the abuse she faced when she was married to the man. ' he was very friendly , very charming , easy to talk to , very soft spoken , and he had a good job and seemed to be pretty good , ' Casey said. you would meet when you got home. ' she said , ' i just want to ask you some things about Michael Wilkie , is that ok ? ' and i said , ' sure , ' Casey recalled\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.predicted_summary[7111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michael Wilkie was found guilty in january of first - degree murder in january for the 2012 killing of his third wife , Shelby Wilkie his second wife , Casey , has opened up about the abuse she faced before divorcing Casey said that he controlled aspects of her life and was physically abusive , particularly when she was pregnant she even said she feared that Michael Wilkie would kill her she said she never warned Shelby Wilkie , but told her she was there if she needed someone to talk to shortly before she *disappeared*'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.summary[7111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_output = __loadStuff(\"abs_output.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['document', 'summary', 'predicted_summary'], dtype='object')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 24\n",
      "291 10\n",
      "2414 8\n",
      "3857 0\n",
      "4624 3\n",
      "8417 29\n",
      "8417 33\n",
      "8417 42\n",
      "8417 55\n",
      "8587 21\n",
      "9488 11\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_output.summary)):\n",
    "    for j in range(len(test_output[\"document\"][i])):\n",
    "        if \"ronaldo\" in test_output[\"document\"][i][j].split(\" \"):\n",
    "            print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"big\" in \"how big egg tried to bring down little mayo\".split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ronaldo left the pitch with a supporter trying to hug him , Bale left it knowing that once again the fingers of blame will be pointing at him after his first half miss after Diego Godin ’s slip',\n",
       " 'on a night when Atletico ’s defence once again showed why it is one of the toughest to break down in Europe all three Real forwards were unable to get the better of their rivals',\n",
       " 'Bale was often the brightest of Real ’s front three but his miss was still the clearest',\n",
       " 'Bale will not find too much consolation in the fact that he linked well with Ronaldo in the first half',\n",
       " 'with Atletico ’s left - back position still bearing a Filipe Luis - shaped hole , Bale attacked at will and he looked for Ronaldo with his crosses as the Portuguese found himself in centre - forward territory regularly throughout the first 45 minutes',\n",
       " 'Ronaldo is confronted by a supporter at the end of the 0 - 0 draw on tuesday night Ronaldo gives the fan a hug after a frustrating night at the Vicente Calderon for Real there seems little doubt the man who is fast approaching Real ’s all - time goals record will finish his playing days as a central striker and he came into this game with a scoring rate of a goal every 74 minutes and seven goals in his last three matches',\n",
       " 'Bale had scored five in his last four games',\n",
       " 'Ronaldo had hit 15 in his 20 Real derbies ; Bale had only netted one goal against Atletico , but what a goal it was – the strike that won the Champions League final',\n",
       " 'but neither man could find the finish to give Real a vital away goal',\n",
       " 'both Bale and Ronaldo scored in extra-time in Lisbon and only an incredible performance from Jan Oblak prevented them from doing so in the first half',\n",
       " 'Bale had embraced his pal Luka Modric just before kick - off and the Croatian midfielder did his best to feed him at every opportunity',\n",
       " 'Bale misses the best chance of the match early in the first half as Jan Oblak saves Ronaldo is squeezed out by Atletico midfielders Mario Suarez ( left ) and Gabi when free - kicks came Real ’s way they were almost all taken by Ronaldo , although Bale was allowed to run over one – and in fairness to ronaldo all the set - pieces were awarded on Ronaldo ’s favoured left - side of the penalty area',\n",
       " 'in the second half as Real ’s momentum faded so did their deadly duo ’s influence on the game',\n",
       " 'Bale apologised to Ronaldo after one misplaced pass',\n",
       " 'he probably should n’t have because he would have received the ball sooner if Ronaldo had not intercepted it before he reached him',\n",
       " 'their understanding on the pitch still looks like it needs some working on but they will remain the biggest threat to Atletico in a week ’s time',\n",
       " \"Bale stretches to control the ball as Atletico 's Turkish winger Arda Turan looks on\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[\"document\"][9488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ronaldo left the pitch with a supporter trying to hug him , Bale left it knowing that once again the fingers of blame will be pointing at him after his first half miss after Diego Godin ’s slip. on a night when Atletico ’s defence once again showed why it is one of the toughest to break down in Europe all three Real forwards were unable to get the better of their rivals. with Atletico ’s left - back position still bearing a Filipe Luis - shaped hole , Bale attacked at will and he looked for Ronaldo with his crosses as the Portuguese found himself in centre - forward territory regularly throughout the first 45 minutes. Bale misses the best chance of the match early in the first half as Jan Oblak saves Ronaldo is squeezed out by Atletico midfielders Mario Suarez ( left ) and Gabi when free - kicks came Real ’s way they were almost all taken by Ronaldo , although Bale was allowed to run over one – and in fairness to ronaldo all the set - pieces were awarded on Ronaldo ’s favoured left - side of the penalty area'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[\"predicted_summary\"][9488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Real drew 0 - 0 at Atletico in Champions League quarter - final first *leg* superstars Ronaldo and Bale both started for Real Ronaldo was kept quiet and Bale , though *impressive* , missed best chance'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output[\"summary\"][9488]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_docs_summaries = [[]]\n",
    "pers_output = pd.DataFrame(columns = ['document', 'targets', 'summary', 'predicted_summary'])\n",
    "\n",
    "pers_output[\"document\"] = test_docs\n",
    "pers_output[\"targets\"] = test_targets\n",
    "pers_output[\"summary\"] = test_summaries\n",
    "\n",
    "# for i in range(len(test_output[\"document\"])):\n",
    "#     temp = []\n",
    "#     for j in range(len(test_output[\"document\"][i])):\n",
    "#         if int(test_output[\"targets\"][i][j]) == 1:\n",
    "#             temp.append(test_docs[i][j])\n",
    "#     test_output[\"predicted_summary\"][i] = temp\n",
    "\n",
    "count = 0\n",
    "counts = 0\n",
    "for i in range(len(test_output[\"document\"])):\n",
    "    temp = []\n",
    "    for j in range(len(test_output[\"document\"][i])):\n",
    "        if int(yo[count-1]) == 1 and answers[count-1][1] > 0.99:\n",
    "            temp.append(test_output[\"document\"][i][j])\n",
    "        count += 1\n",
    "    pers_output[\"predicted_summary\"][i] = temp\n",
    "\n",
    "# c = 0\n",
    "\n",
    "# for i in range(len(test_output[\"document\"])):\n",
    "#     temp = []\n",
    "#     index = list(range(c, c+len(test_output[\"document\"][i])))\n",
    "#     try:\n",
    "#         index = np.sort(np.argpartition(answers[index][:, 1], -4)[-4:])\n",
    "#     except:\n",
    "#         index = np.sort(index)\n",
    "#     for j in range(len(test_output[\"document\"][i])):\n",
    "#         if j in index:\n",
    "#             temp.append(test_output[\"document\"][i][j])\n",
    "#     test_output[\"predicted_summary\"][i] = temp\n",
    "#     c += len(test_output[\"document\"][i])\n",
    "    \n",
    "    \n",
    "for i in range(len(pers_output[\"predicted_summary\"])):\n",
    "    pers_output[\"predicted_summary\"][i] = \". \".join(pers_output[\"predicted_summary\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ronaldo bagged five goals in 9 - 1 victory against Granada Benzema scored twice for Carlo Ancelotti 's Real Madrid side Benzema *believes* Ronaldo ' deserves everything he has achieved '\""
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.summary[2414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"it was the first time in his career that Ronaldo has scored five goals in a single match and saw him become only the third player to reach the 300 - goal mark for Real Madrid , a tally achieved in only 287 appearances. the Frenchman added : ' Him ( Ronaldo ) , Gareth Bale and me , we 're in good form , like always. ' Real Madrid 's performance was a timely one , coming after they had lost three of their previous five matches in La Liga and the Champions League - including a 2 - 1 loss to bitter rivals Barcelona in their last outing. sunday 's win saw Real Madrid close the gap to Barcelona back to one point ahead of the league leaders ' clash at Celta Vigo on sunday evening , and coach Carlo Ancelotti is looking to the future with optimism\""
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.predicted_summary[2414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Benzema hailed team - mate Ronaldo as a ' phenomenon ' after the Portuguese struck five goals in Real Madrid 's 9 - 1 mauling of Granada. it was the first time in his career that Ronaldo has scored five goals in a single match and saw him become only the third player to reach the 300 - goal mark for Real Madrid , a tally achieved in only 287 appearances. on sunday , Benzema said on his club 's website : ' Ronaldo is a phenomenon , he is always looking for goals and ways to help the team. he deserves everything he has achieved. ' Ronaldo ( centre ) scored five goals during Real Madrid 's 9 - 1 La Liga victory against Granada Benzema also scored twice after Gareth Bale had opening the scoring as Real Madrid 's much - vaunted ' BBC ' strikeforce combined to score eight of their side 's nine goals , with the other coming from a Diego Mainz own goal. the Frenchman added : ' Him ( Ronaldo ) , Gareth Bale and me , we 're in good form , like always. we 're helping the team and sometimes we score and other times we do n't , but we 're in good shape to continue like that until the end of the season. ' Ronaldo , meanwhile , was quick to highlight the role his team - mates played in his five - goal haul as he inched closer to becoming the club 's all - time record scorer. Benzema , who scored twice himself , hailed his Real Madrid team - mate ronaldo as a ' phenomenon ' Ronaldo performs his trademark celebration as his team - mates watch during the 9 - 1 rout at the Bernabeu Raul currently leads the way with 323 goals from 741 appearances while Alfredo di Stefano is second with 308 goals from 396 matches. Ronaldo wrote on Twitter : ' happy to have scored 5 goals with this excelent team work. sunday 's win saw Real Madrid close the gap to Barcelona back to one point ahead of the league leaders ' clash at Celta Vigo on sunday evening , and coach Carlo Ancelotti is looking to the future with optimism. Gareth Bale scored for Wales last week and kept up his scoring form with a goal against Granada he said : ' everything went to plan. but today we have to point out the good play , the team are back to playing as desired , just like they have played many times before. what mattered most was winning and playing well and we have achieved that. so , what can i say ... this is the first time he has scored five goals in a game and that is good news for everyone : for him , for the team and in terms of the upcoming fixtures '. Ronaldo now has 24 La Liga hat - tricks - drawing level with Barcelona star Lionel Messi\""
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pers_output.predicted_summary[2414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Benzema hailed team - mate Ronaldo as a ' phenomenon ' after the Portuguese struck five goals in Real Madrid 's 9 - 1 mauling of Granada\",\n",
       " 'it was the first time in his career that Ronaldo has scored five goals in a single match and saw him become only the third player to reach the 300 - goal mark for Real Madrid , a tally achieved in only 287 appearances',\n",
       " \"on sunday , Benzema said on his club 's website : ' Ronaldo is a phenomenon , he is always looking for goals and ways to help the team\",\n",
       " 'he deserves everything he has achieved',\n",
       " \"' Ronaldo ( centre ) scored five goals during Real Madrid 's 9 - 1 La Liga victory against Granada Benzema also scored twice after Gareth Bale had opening the scoring as Real Madrid 's much - vaunted ' BBC ' strikeforce combined to score eight of their side 's nine goals , with the other coming from a Diego Mainz own goal\",\n",
       " \"the Frenchman added : ' Him ( Ronaldo ) , Gareth Bale and me , we 're in good form , like always\",\n",
       " \"we 're helping the team and sometimes we score and other times we do n't , but we 're in good shape to continue like that until the end of the season\",\n",
       " \"' Ronaldo , meanwhile , was quick to highlight the role his team - mates played in his five - goal haul as he inched closer to becoming the club 's all - time record scorer\",\n",
       " \"Benzema , who scored twice himself , hailed his Real Madrid team - mate ronaldo as a ' phenomenon ' Ronaldo performs his trademark celebration as his team - mates watch during the 9 - 1 rout at the Bernabeu Raul currently leads the way with 323 goals from 741 appearances while Alfredo di Stefano is second with 308 goals from 396 matches\",\n",
       " \"Ronaldo wrote on Twitter : ' happy to have scored 5 goals with this excelent team work\",\n",
       " 'thank you for all your support',\n",
       " \"' Real Madrid 's performance was a timely one , coming after they had lost three of their previous five matches in La Liga and the Champions League - including a 2 - 1 loss to bitter rivals Barcelona in their last outing\",\n",
       " \"sunday 's win saw Real Madrid close the gap to Barcelona back to one point ahead of the league leaders ' clash at Celta Vigo on sunday evening , and coach Carlo Ancelotti is looking to the future with optimism\",\n",
       " \"Gareth Bale scored for Wales last week and kept up his scoring form with a goal against Granada he said : ' everything went to plan\",\n",
       " 'my team are in good physical shape , the players are fresh and we showed that throughout the match',\n",
       " \"' we played with a good tempo and scored bags of goals\",\n",
       " 'we come away from this happy but this is just one game and we have other important ones coming up',\n",
       " \"' it 's simple mathematics\",\n",
       " \"it 's better to win nine games 1 - 0 than one 9 - 1\",\n",
       " 'but today we have to point out the good play , the team are back to playing as desired , just like they have played many times before',\n",
       " 'what mattered most was winning and playing well and we have achieved that',\n",
       " \"' on Ronaldo , the Italian added : ' he has improved just as the team have\",\n",
       " \"so , what can i say ... this is the first time he has scored five goals in a game and that is good news for everyone : for him , for the team and in terms of the upcoming fixtures '\",\n",
       " 'Ronaldo now has 24 La Liga hat - tricks - drawing level with Barcelona star Lionel Messi']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output.document[2414]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
